# -*- coding: utf-8 -*-
"""text_preprocessing.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1shXOtqmm5JYzLCQ590zDbhgg4-gGvA60
"""

kohli_sent = "Kohli made his Test debut in 2011."
kohli_para = "Kohli made his Test debut in 2011. He reached the number one spot in the ICC rankings for ODI batsmen for the first time in 2013. He has won Man of the Tournament twice at the ICC World Twenty20 (in 2014 and 2016). He also holds the world record of being the fastest to score 24,000 international career runs. He also is the leading run scorer of all time in T20s, as well as the current leading run scorer in T20 World Cups."
hist_para = "I have three visions for India. In 3000 years of our history, people from all over the world have come and invaded us, captured our lands, conquered our minds. From Alexander onwards, the Greeks, the Turks, the Moguls, the Portuguese, the British, the French, the Dutch, all of them came and looted us, took over what was ours."

"""##Convert text to lower case and remove leading, trailing whitespace"""

kohli_sent.lower().strip()

"""##Remove Contraction"""

!pip install contractions
import contractions

contractions.fix("The Giants won't lose to this week because the giants are calling for a victory.")

"""##Tokenization"""

from nltk.tokenize import word_tokenize #word_tokenize divide string at word, number, punctuation level
print(word_tokenize(kohli_sent))
print(word_tokenize(kohli_para))

from nltk.tokenize import sent_tokenize #sent_tokenize divide string at sentence level
print(sent_tokenize(kohli_para))

"""##Remove Punctuation"""

import string
s = set(string.punctuation)
print(s)

kohli_para.translate(str.maketrans('','', string.punctuation))

"""##Remove stopwords"""

import nltk
nltk.download('stopwords')
from nltk.corpus import stopwords
eng_stopwords= sorted(set(stopwords.words('english')))
print(eng_stopwords)

' '.join([word for word in word_tokenize(kohli_para) if word not in eng_stopwords])

"""##Stemming"""

import nltk
from nltk.stem import SnowballStemmer
nltk.download('punkt')
stemmer = SnowballStemmer(language='english')
stemmer.stem("History"), stemmer.stem("Historical"), stemmer.stem("Final"), stemmer.stem("Finally")

#stemmer sees the entire sentence as a word, so it returns it as it is. We need to stem each word in the sentence and 
#return a combined sentence.To separate the sentence into words, you can use tokenizer.
stemmer.stem(kohli_sent)

token_words = word_tokenize(hist_para)
stem_sent = ' '.join([stemmer.stem(word) for word in token_words])
stem_sent

"""##Lemmatization"""

import nltk
nltk.download('punkt')
nltk.download('stopwords')
nltk.download('wordnet')
nltk.download('omw-1.4')
from nltk.stem import WordNetLemmatizer
from nltk.corpus import stopwords

eng_stopwords= stopwords.words('english')
print(eng_stopwords)

lemma = WordNetLemmatizer()
print([lemma.lemmatize(word, pos='v') for word in word_tokenize(kohli_para) if 
       (word not in s) and word not in eng_stopwords and not word.isnumeric()])

#stemming result
print([stemmer.stem(word) for word in word_tokenize(kohli_para) if 
       (word not in s) and word not in eng_stopwords and not word.isnumeric()])

"""##Stemming vs Lemmatization"""

print(lemma.lemmatize('historical', pos='v'), stemmer.stem('historical'))
print(lemma.lemmatize('history', pos='v'), stemmer.stem('history'))
print(lemma.lemmatize('playing', pos='v'), stemmer.stem('playing'))
print(lemma.lemmatize('caring', pos='v'), stemmer.stem('caring'))
print(lemma.lemmatize('fairly', pos='v'), stemmer.stem('fairly'))
print(lemma.lemmatize('generous', pos='v'), stemmer.stem('generous'))